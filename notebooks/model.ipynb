{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "728543c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FINAL MODEL PERFORMANCE =====\n",
      "MAE  : 10.6110\n",
      "RMSE : 13.6509\n",
      "R²   : 0.9885\n",
      "\n",
      "===== TOP FEATURES =====\n",
      "             Feature  Importance\n",
      "8              lag_1    0.217167\n",
      "10    rolling_mean_3    0.210167\n",
      "9              lag_2    0.201747\n",
      "15       roll_mean_3    0.196342\n",
      "16        roll_std_3    0.161702\n",
      "18        roll_std_6    0.001173\n",
      "20       roll_std_12    0.001017\n",
      "13            lag_12    0.000955\n",
      "1   Temperature (°C)    0.000951\n",
      "14            lag_24    0.000923\n",
      "12             lag_6    0.000905\n",
      "11             lag_3    0.000893\n",
      "19      roll_mean_12    0.000812\n",
      "2       Humidity (%)    0.000811\n",
      "17       roll_mean_6    0.000810\n",
      "Saving the model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/model.pkl']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# ============================================\n",
    "# 1. LOAD DATA\n",
    "# ============================================\n",
    "df = pd.read_csv(\"../dataset/preprocessed_energy_data.csv\")\n",
    "\n",
    "# ============================================\n",
    "# 2. FEATURE ENGINEERING\n",
    "# ============================================\n",
    "\n",
    "# Additional lags (1, 2, 3, 6, 12, 24 hours)\n",
    "for lag in [1, 2, 3, 6, 12, 24]:\n",
    "    df[f'lag_{lag}'] = df['Energy_Usage (kWh)'].shift(lag)\n",
    "\n",
    "# Rolling means & std smoothing\n",
    "for w in [3, 6, 12]:\n",
    "    df[f'roll_mean_{w}'] = df['Energy_Usage (kWh)'].rolling(window=w).mean()\n",
    "    df[f'roll_std_{w}']  = df['Energy_Usage (kWh)'].rolling(window=w).std()\n",
    "\n",
    "# Seasonal Fourier features (captures patterns very well)\n",
    "df[\"sin_hour\"] = np.sin(2 * np.pi * df[\"Hour\"] / 24)\n",
    "df[\"cos_hour\"] = np.cos(2 * np.pi * df[\"Hour\"] / 24)\n",
    "\n",
    "df[\"sin_day\"] = np.sin(2 * np.pi * df[\"DayOfWeek\"] / 7)\n",
    "df[\"cos_day\"] = np.cos(2 * np.pi * df[\"DayOfWeek\"] / 7)\n",
    "\n",
    "# Drop NaNs created from lags\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# ============================================\n",
    "# 3. OUTLIER HANDLING (CAPPING, NOT DROPPING)\n",
    "# ============================================\n",
    "Q1 = df['Energy_Usage (kWh)'].quantile(0.25)\n",
    "Q3 = df['Energy_Usage (kWh)'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "df['Energy_Usage (kWh)'] = np.where(df['Energy_Usage (kWh)'] > upper, upper,\n",
    "                             np.where(df['Energy_Usage (kWh)'] < lower, lower,\n",
    "                                      df['Energy_Usage (kWh)']))\n",
    "\n",
    "# ============================================\n",
    "# 4. TRAIN / TEST SPLIT\n",
    "# ============================================\n",
    "X = df.drop(columns=[\"Timestamp\", \"Energy_Usage (kWh)\"])\n",
    "y = df[\"Energy_Usage (kWh)\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, shuffle=False   # smaller test = more training data\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# 5. SAME RANDOM FOREST MODEL (\n",
    "# ============================================\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=400,\n",
    "    max_depth=15,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ============================================\n",
    "# 6. EVALUATION\n",
    "# ============================================\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n===== FINAL MODEL PERFORMANCE =====\")\n",
    "print(f\"MAE  : {mae:.4f}\")\n",
    "print(f\"RMSE : {rmse:.4f}\")\n",
    "print(f\"R²   : {r2:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "importances = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Importance\": model.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"\\n===== TOP FEATURES =====\")\n",
    "print(importances.head(15))\n",
    "\n",
    "print(\"Saving the model\")\n",
    "joblib.dump(model,\"../models/model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330d84f2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
